{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GaneshArvapalli/AggClustDemo/blob/master/derivatives_graphs_data_request.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install urllib3 bs4 requests networkx matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWKnUYmUQEAW"
   },
   "outputs": [],
   "source": [
    "# Ganesh Arvapalli\n",
    "# NeuroData - 12/7/18\n",
    "\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYdmQ4E09V8b"
   },
   "outputs": [],
   "source": [
    "# Some nice graph statistics that I found on the networkx doc page \n",
    "# (https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.html)\n",
    "\n",
    "def generate_stats(g):\n",
    "  # Average degree\n",
    "  t = time.time()\n",
    "  N,K = g.order(), g.size()\n",
    "  if N != 0:\n",
    "    avg_deg = float(K)/N\n",
    "    print(\"Average degree:\", avg_deg, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Average neightbor degree\n",
    "  t = time.time()\n",
    "  andeg = nx.average_neighbor_degree(g)\n",
    "  if len(andeg) != 0:\n",
    "    avg_andeg = sum(andeg.values())/len(andeg)\n",
    "    print(\"Average neighbor degree:\", avg_andeg, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Average degree connectivity\n",
    "  t = time.time()\n",
    "  adc = nx.average_degree_connectivity(g)\n",
    "  if len(adc) != 0:\n",
    "    avg_adc = sum(adc.values())/len(adc)\n",
    "    print(\"Average degree connectivity:\", avg_adc, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Clustering coefficient\n",
    "  t = time.time()\n",
    "  ccs = nx.clustering(g)\n",
    "  if len(ccs) != 0:\n",
    "    avg_cc = sum(ccs.values())/len(ccs)\n",
    "    print(\"Average clustering coefficient:\", avg_cc, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Betweenness centrality\n",
    "  t = time.time()\n",
    "  bet_cen = nx.betweenness_centrality(g)\n",
    "  if len(bet_cen) != 0:\n",
    "    avg_bc = sum(bet_cen.values())/len(bet_cen)\n",
    "    print(\"Betweenness centrality:\", avg_bc, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Closeness centrality\n",
    "  t = time.time()\n",
    "  clo_cen = nx.closeness_centrality(g)\n",
    "  if len(clo_cen) != 0:\n",
    "    avg_clc = sum(clo_cen.values())/len(clo_cen)\n",
    "    print(\"Closeness centrality:\", avg_clc, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Eigenvector centrality\n",
    "  t = time.time()\n",
    "  eig_cen = nx.eigenvector_centrality(g)\n",
    "  if len(eig_cen) != 0:\n",
    "    avg_ec = sum(eig_cen.values())/len(eig_cen)\n",
    "    print(\"Eigenvector centrality:\", avg_ec, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Communicability\n",
    "#   t = time.time()\n",
    "#   cmb = nx.communicability(g)\n",
    "#   total = 0\n",
    "#   for i in cmb.values():\n",
    "#     if len(i.values()) != 0:\n",
    "#       total += sum(i.values())/len(i.values())\n",
    "#   print(\"Communicability:\", total, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Estrada Index\n",
    "  t = time.time()\n",
    "  ei = nx.estrada_index(g)\n",
    "  print(\"Estrada Index:\", ei, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Dispersion\n",
    "  t = time.time()\n",
    "  dis = nx.dispersion(g)\n",
    "  total = 0\n",
    "  for i in dis.values():\n",
    "    if len(i.values()) != 0:\n",
    "      total += sum(i.values())/len(i.values())\n",
    "  print(\"Dispersion:\", total, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Chordality\n",
    "  t = time.time()\n",
    "  if len(list(g.nodes_with_selfloops())) == 0:\n",
    "    if nx.is_chordal(g):\n",
    "      chordal = 1\n",
    "      print(\"Chordality:\", 1, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  else:\n",
    "    chordal = 0\n",
    "    print(\"Chordality:\", 0, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Average number of cliques\n",
    "  t = time.time()\n",
    "  nc = nx.number_of_cliques(g)\n",
    "  if len(nc) != 0:\n",
    "    avg_nc = sum(nc.values())/len(nc)\n",
    "#     print(\"Number of cliques:\", avg_nc, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Radius (min ecc)\n",
    "  t = time.time()\n",
    "  r = nx.radius(g)\n",
    "#   print(\"Radius:\", r, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Diameter (max ecc)\n",
    "  t = time.time()\n",
    "  d = nx.diameter(g)\n",
    "#   print(\"Diameter:\", d, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Average Eccentricity\n",
    "  t = time.time()\n",
    "  e = nx.eccentricity(g)\n",
    "  if len(e) != 0:\n",
    "    avg_e = sum(e.values())/len(e)\n",
    "#     print(\"Average eccentricity:\", avg_e, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Eulerian\n",
    "  t = time.time()\n",
    "#   if nx.is_eulerian(g):\n",
    "#     print(\"Eulerianness:\", 1, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "#   else:\n",
    "#     print(\"Eulerianness:\", 0, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Num isolates\n",
    "  t = time.time()\n",
    "  n_iso = len(list(nx.isolates(g)))\n",
    "#   print(\"Number of isolates:\", n_iso, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # # Rich-club coefficient:\n",
    "  # t = time.time()\n",
    "  # rcc = nx.rich_club_coefficient(g)\n",
    "  # avg_rcc = sum(rcc.values())/len(rcc)\n",
    "  # print(\"Rich-club coefficient:\", avg_rcc, \"took\", round(time.time() - t, 3), \"seconds\"\n",
    "  # Shortest path length:\n",
    "  t = time.time()\n",
    "  avg_spl = nx.average_shortest_path_length(g)\n",
    "#   print(\"Average shortest path length:\", avg_spl, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Closeness vitality\n",
    "#   t = time.time()\n",
    "#   cv = nx.closeness_vitality(g)\n",
    "#   if len(cv) != 0:\n",
    "#     avg_cv = sum(cv.values())/len(cv)\n",
    "#     print(\"Closeness vitality:\", avg_cv, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ejkn0sbqasb"
   },
   "outputs": [],
   "source": [
    "# Format graph statistics as numpy array (to be inserted into data matrix)\n",
    "# (https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.html)\n",
    "\n",
    "def stat_vec(g):\n",
    "  if len(g.nodes()) == 0:\n",
    "    return np.zeros((1,15))\n",
    "  # Average degree\n",
    "  N,K = g.order(), g.size()\n",
    "  if N != 0:\n",
    "    avg_deg = float(K)/N\n",
    "  # Average neightbor degree\n",
    "  andeg = nx.average_neighbor_degree(g)\n",
    "  if len(andeg) != 0:\n",
    "    avg_andeg = sum(andeg.values())/len(andeg)\n",
    "  # Average degree connectivity\n",
    "  adc = nx.average_degree_connectivity(g)\n",
    "  if len(adc) != 0:\n",
    "    avg_adc = sum(adc.values())/len(adc)\n",
    "  # Clustering coefficient\n",
    "  ccs = nx.clustering(g)\n",
    "  if len(ccs) != 0:\n",
    "    avg_cc = sum(ccs.values())/len(ccs)\n",
    "  # Betweenness centrality\n",
    "  bet_cen = nx.betweenness_centrality(g)\n",
    "  if len(bet_cen) != 0:\n",
    "    avg_bc = sum(bet_cen.values())/len(bet_cen)\n",
    "  # Closeness centrality\n",
    "  clo_cen = nx.closeness_centrality(g)\n",
    "  if len(clo_cen) != 0:\n",
    "    avg_clc = sum(clo_cen.values())/len(clo_cen)\n",
    "  # Eigenvector centrality\n",
    "  if len(g.nodes()) != 0:\n",
    "    eig_cen = nx.eigenvector_centrality(g)\n",
    "    if len(eig_cen) != 0:\n",
    "      avg_ec = sum(eig_cen.values())/len(eig_cen)\n",
    "  else:\n",
    "    avg_ec = 0\n",
    "  # Communicability\n",
    "#   t = time.time()\n",
    "#   cmb = nx.communicability(g)\n",
    "#   total = 0\n",
    "#   for i in cmb.values():\n",
    "#     if len(i.values()) != 0:\n",
    "#       total += sum(i.values())/len(i.values())\n",
    "#   print(\"Communicability:\", total, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Estrada Index\n",
    "  ei = nx.estrada_index(g)\n",
    "  # Dispersion\n",
    "  dis = nx.dispersion(g)\n",
    "  total = 0\n",
    "  for i in dis.values():\n",
    "    if len(i.values()) != 0:\n",
    "      total += sum(i.values())/len(i.values())\n",
    "  # Chordality\n",
    "#   if len(list(g.nodes_with_selfloops())) == 0:\n",
    "#     if nx.is_chordal(g):\n",
    "#       chordal = 1\n",
    "#   else:\n",
    "#     chordal = 0\n",
    "  # Average number of cliques\n",
    "  nc = nx.number_of_cliques(g)\n",
    "  if len(nc) != 0:\n",
    "    avg_nc = sum(nc.values())/len(nc)\n",
    "  # Radius (min ecc)\n",
    "  if nx.is_connected(g):\n",
    "    r = nx.radius(g)\n",
    "  else:\n",
    "    r = 0\n",
    "  # Diameter (max ecc)\n",
    "  if nx.is_connected(g):\n",
    "    d = nx.diameter(g)\n",
    "  else:\n",
    "    d = 0\n",
    "  # Average Eccentricity\n",
    "  if nx.is_connected(g):\n",
    "    e = nx.eccentricity(g)\n",
    "    if len(e) != 0:\n",
    "      avg_e = sum(e.values())/len(e)\n",
    "  else:\n",
    "    avg_e = 0\n",
    "  # Eulerian\n",
    "#   if nx.is_eulerian(g):\n",
    "#     print(\"Eulerianness:\", 1, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "#   else:\n",
    "#     print(\"Eulerianness:\", 0, \"took\", round(time.time() - t, 3), \"seconds\")\n",
    "  # Num isolates\n",
    "  n_iso = len(list(nx.isolates(g)))\n",
    "  # # Rich-club coefficient:\n",
    "  # rcc = nx.rich_club_coefficient(g)\n",
    "  # avg_rcc = sum(rcc.values())/len(rcc)\n",
    "  # Shortest path length:\n",
    "  if nx.is_connected(g):\n",
    "    avg_spl = nx.average_shortest_path_length(g)\n",
    "  else:\n",
    "    avg_spl = 0\n",
    "  # Closeness vitality\n",
    "#   cv = nx.closeness_vitality(g)\n",
    "#   if len(cv) != 0:\n",
    "#     avg_cv = sum(cv.values())/len(cv)\n",
    "\n",
    "\n",
    "  stats = [avg_deg, avg_andeg, avg_adc, avg_cc, avg_bc, avg_clc, avg_ec, ei, total, r, d, avg_e, avg_spl]\n",
    "  stats = [float(i) for i in stats]\n",
    "\n",
    "  return np.array(stats)\n",
    "#  nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "IjThOppYaZM6",
    "outputId": "a6472163-98a2-433d-b396-185f36831dce"
   },
   "outputs": [],
   "source": [
    "# Still need to do derivatives/func/connectomes/, outputs_dmri/dwi/roi-connectomes, outputs_fmri/func/connectomes, testout/dwi/roi-connectomes/, testout/func/connectomes\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "    \n",
    "# Open connection to link and get data\n",
    "groups=[\"AAL\", \"CPAC200\", \"DS00071\", \"DS00096\", \"DS00108\", \n",
    "        \"DS00140\", \"DS00195\", \"DS00278\", \"DS00350\", \"DS00446\", \n",
    "        \"DS00583\", \"DS00833\", \"DS01216\", \"DS01876\", \"DS03231\", \n",
    "        \"DS06481\", \"DS16784\", \"DS72784\", \"HarvardOxford\", \n",
    "        \"JHU\", \"Talairach\", \"desikan\", \"hemispheric\", \"slab1068\", \n",
    "        \"slab907\", \"tissue\"]\n",
    "# Replace NDARAA536PTU with other subject names\n",
    "subjects=['NDARAA536PTU', 'NDARAD481FXF', 'NDARAE199TDD', 'NDARAJ366ZFA', \n",
    "          'NDARAK187ZLP', 'NDARAM277WZT', 'NDARAR025WX4', 'NDARAT100AEQ', \n",
    "          'NDARAT299YRR', 'NDARAV747WVL', 'NDARAV894XWD', 'NDARAV945MCQ', \n",
    "          'NDARBA507GCT', 'NDARBA521RA8', 'NDARBB854DRN', 'NDARBG702FED', \n",
    "          'NDARBK669XJQ', 'NDARBM213BEA', 'NDARBN100LCD', 'NDARBU112XZE', \n",
    "          'NDARBV364MBC', 'NDARBZ216FW8', 'NDARCA186WGH', 'NDARCA789EE0', \n",
    "          'NDARCB959FY4', 'NDARCD401HGZ', 'NDARCJ007GF8', 'NDARCL080RHP', \n",
    "          'NDARCP360AFD', 'NDARCT933HF2', 'NDARCW419GBD', 'NDARDA695XTL', \n",
    "          'NDARDB804YHE', 'NDARDC360DGB', 'NDARDH328DR9', 'NDARDJ825GBP', \n",
    "          'NDARDK983BDA', 'NDARDM425CG2', 'NDARDN702GXX', 'NDARDN770HY6', \n",
    "          'NDARDR658DRA', 'NDARDT800YVF', 'NDARDU799BZF', 'NDARDX469TC1', \n",
    "          'NDARDX561MRY', 'NDARDX770PJK', 'NDARDZ946KVL', 'NDAREC182WW2', \n",
    "          'NDARED047DTH', 'NDARED632KNG', 'NDAREF057VX5', 'NDAREK375DKR', \n",
    "          'NDAREK544ENR', 'NDAREK918EC2', 'NDAREK947FYP', 'NDAREL063PMX', \n",
    "          'NDAREM018TJQ', 'NDAREM141CKP', 'NDARET653TAM', 'NDARET949LMU', \n",
    "          'NDAREU211JMY', 'NDAREY962BM7', 'NDAREZ098ZPE', 'NDARFA464HJQ', \n",
    "          'NDARFB107PVH', 'NDARFB500HHN', 'NDARFH674DWX', 'NDARFL411AT1', \n",
    "          'NDARFM080VAF', 'NDARFN452VPC', 'NDARFR109LKT', 'NDARFT834NT1', \n",
    "          'NDARFU789PRX', 'NDARFW130NGG', 'NDARFW292PBD', 'NDARFW444PN1', \n",
    "          'NDARFY612EMR', 'NDARFZ296UNG', 'NDARGA967MGC', 'NDARGE366WNC', \n",
    "          'NDARGL834CMQ', 'NDARGL963HU4', 'NDARGM498YFL', 'NDARGM610LF0', \n",
    "          'NDARGT022BEW', 'NDARGY054ENV', 'NDARGY148EVU', 'NDARHB993EV0', \n",
    "          'NDARHD059PEQ', 'NDARHF023VG3', 'NDARHJ523XGB', 'NDARHJ946UPH', \n",
    "          'NDARHK598YJC', 'NDARHL238VL2', 'NDARHL358LGQ', 'NDARHM273AXL', \n",
    "          'NDARHM304AXP', 'NDARHM615PJH', 'NDARHP176DPE', 'NDARHP558MGA', \n",
    "          'NDARHP656DLC']\n",
    "\n",
    "# edgelist_data = {}\n",
    "data_matrix = np.zeros((1,13))\n",
    "data_array = np.zeros((1, 13))\n",
    "count = 0\n",
    "# for i in groups:\n",
    "i = \"JHU\"    # Set this to whatever group/folder you want\n",
    "for j in subjects:\n",
    "  temp = {}\n",
    "  r = http.request(\"GET\", \"http://neurodatadesign.s3.amazonaws.com/hbn/derivatives/graphs/\" + i + \"/sub-\" + j + \"_acq-64dir_dwi_\"+ i + \".edgelist\")\n",
    "  # print(r.status,  \"http://neurodatadesign.s3.amazonaws.com/hbn/derivatives/graphs/\" + i + \"/sub-\" + j + \"_acq-64dir_dwi_\" + i + \".edgelist\")\n",
    "  if r.status == 200:\n",
    "#       temp[j] = r.data.decode('utf-8').split('\\n')\n",
    "#       edgelist_data[i] = temp\n",
    "    try:\n",
    "      filedata = r.data.decode('utf-8').split('\\n')\n",
    "      # Do what you want with the file data from this point on\n",
    "      g = nx.parse_edgelist(filedata,  nodetype = int, data=(('weight',float),))\n",
    "#         plt.figure()\n",
    "      count += 1\n",
    "  \n",
    "      stats = stat_vec(g)\n",
    "      data_matrix = np.vstack([data_matrix, stats])\n",
    "      # data_array = np.concatenate((data_array, stats), axis=0)\n",
    "#         plt.show()\n",
    "    except ValueError:\n",
    "      print(\"ValueError encountered!\")\n",
    "      print(filedata)\n",
    "      print(j)\n",
    "      continue\n",
    "    except TypeError:\n",
    "      print(\"TypeError encountered!\")\n",
    "      for i in stats:\n",
    "        print(type(i))\n",
    "      break\n",
    "      \n",
    "data_matrix = np.delete(data_matrix, 0, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Q0zUE2bE2SKb",
    "outputId": "36e0a60e-740f-495f-c9b9-399fc6e03abe"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "print(\"Done collecting data\")\n",
    "print(\"Data shape:\", data_matrix.shape)\n",
    "# print(data_matrix)\n",
    "print(\"Total number of graphs read:\", count)\n",
    "print(\"Number of features:\", data_matrix.shape[1])\n",
    "\n",
    "with open('hbn_jhu_data_matrix.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([data_matrix], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "_CACPGcF3E9D",
    "outputId": "0272f691-4d86-4c9f-dd25-c01e8e6b8ae7"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import math\n",
    "\n",
    "best_ss = []\n",
    "plt.figure()\n",
    "plt.title('Num Clusters vs. Silhouette Score (Agg, Ward), w/ N components')\n",
    "for i in range(2,6):\n",
    "  x = range(2,15)\n",
    "  y = []\n",
    "  for j in x:\n",
    "    pca = PCA(n_components=i, svd_solver='full')\n",
    "    X = pca.fit_transform(data_matrix)\n",
    "    clustering = AgglomerativeClustering(n_clusters=j).fit(X)\n",
    "    # print(clustering.labels_)\n",
    "    y.append(silhouette_score(X, clustering.labels_, metric='sqeuclidean'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.xlabel('# of clusters')\n",
    "  plt.ylabel('Silhouette Score')\n",
    "  plt.plot(x, y)\n",
    "\n",
    "  best_ss.append(max(y))\n",
    "\n",
    "  \n",
    "plt.legend(range(2,6))\n",
    "plt.show()\n",
    "  \n",
    "plt.figure()\n",
    "plt.title('Best Silhouette Score per Num Components: ' + str(round(max(best_ss), 3)))\n",
    "plt.xlabel('# of components')\n",
    "plt.ylabel('Max Silhouette Score')\n",
    "plt.plot(range(2,6), best_ss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "XWNr7Pii4cjY",
    "outputId": "7bd76eff-f9b3-4547-f0cd-61fa5c1925c3"
   },
   "outputs": [],
   "source": [
    "# Best case scenario\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "X = pca.fit_transform(data_matrix)\n",
    "aggclust = AgglomerativeClustering(n_clusters=4).fit(X)\n",
    "# print(clustering.labels_)\n",
    "print(silhouette_score(X, aggclust.labels_, metric='sqeuclidean'))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Agglomerative Ward-Linked Clustering Results on PCA 2D (4 clusters)\")\n",
    "plt.xlabel(\"Eigenvalue 1\")\n",
    "plt.ylabel(\"Eigenvalue 2\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=aggclust.labels_,cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "DdFBuqBYzhzT",
    "outputId": "36c5d0c9-2eb7-4196-c9a3-07b3f26628fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "best_ss = []\n",
    "plt.figure()\n",
    "plt.title('Num Clusters vs. Silhouette Score (K-Means) w/ N components')\n",
    "for i in range(2,6):\n",
    "  x = range(2,15)\n",
    "  y = []\n",
    "  for j in x:\n",
    "    pca = PCA(n_components=i, svd_solver='full')\n",
    "    X = pca.fit_transform(data_matrix)\n",
    "    clustering = KMeans(n_clusters=j).fit(X)\n",
    "    # print(clustering.labels_)\n",
    "    y.append(silhouette_score(X, clustering.labels_, metric='sqeuclidean'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.xlabel('# of clusters')\n",
    "  plt.ylabel('Silhouette Score')\n",
    "  plt.plot(x, y)\n",
    "\n",
    "  best_ss.append(max(y))\n",
    "\n",
    "  \n",
    "plt.legend(range(2,6))\n",
    "plt.show()\n",
    "  \n",
    "plt.figure()\n",
    "plt.title('Best Silhouette Score per Num Components: ' + str(round(max(best_ss), 3)))\n",
    "plt.xlabel('# of components')\n",
    "plt.ylabel('Max Silhouette Score')\n",
    "plt.plot(range(2,6), best_ss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "pIb85AS5z3jl",
    "outputId": "03dd334a-f85a-4760-b961-c524ce909a60"
   },
   "outputs": [],
   "source": [
    "# Best case scenario\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "X = pca.fit_transform(data_matrix)\n",
    "kmeans = KMeans(n_clusters=2).fit(X)\n",
    "# print(clustering.labels_)\n",
    "print(silhouette_score(X, kmeans.labels_, metric='sqeuclidean'))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"K-Means Clustering Results on PCA 2D (2 clusters)\")\n",
    "plt.xlabel(\"Eigenvalue 1\")\n",
    "plt.ylabel(\"Eigenvalue 2\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_,cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "aE8Ew6u31Bbx",
    "outputId": "75f956d4-49e4-483b-b32c-a6e9d2b93b27"
   },
   "outputs": [],
   "source": [
    "best_ss = []\n",
    "plt.figure()\n",
    "plt.title('Num Clusters vs. Silhouette Score (Agg, Complete), w/ N components')\n",
    "for i in range(2,6):\n",
    "  x = range(2,15)\n",
    "  y = []\n",
    "  for j in x:\n",
    "    pca = PCA(n_components=i, svd_solver='full')\n",
    "    X = pca.fit_transform(data_matrix)\n",
    "    clustering = AgglomerativeClustering(n_clusters=j, linkage=\"complete\").fit(X)\n",
    "    # print(clustering.labels_)\n",
    "    y.append(silhouette_score(X, clustering.labels_, metric='sqeuclidean'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.xlabel('# of clusters')\n",
    "  plt.ylabel('Silhouette Score')\n",
    "  plt.plot(x, y)\n",
    "\n",
    "  best_ss.append(max(y))\n",
    "\n",
    "  \n",
    "plt.legend(range(2,6))\n",
    "plt.show()\n",
    "  \n",
    "plt.figure()\n",
    "plt.title('Best Silhouette Score per Num Components: ' + str(round(max(best_ss), 3)))\n",
    "plt.xlabel('# of components')\n",
    "plt.ylabel('Max Silhouette Score')\n",
    "plt.plot(range(2,6), best_ss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "zuSafmKc2nAj",
    "outputId": "bb3a2feb-4f9a-456d-8784-55d90207701b"
   },
   "outputs": [],
   "source": [
    "# Best case scenario\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "X = pca.fit_transform(data_matrix)\n",
    "aggclust2 = AgglomerativeClustering(n_clusters=2, linkage=\"complete\").fit(X)\n",
    "# print(clustering.labels_)\n",
    "print(silhouette_score(X, aggclust2.labels_, metric='sqeuclidean'))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Agglomerative Complete-Linked Clustering Results on PCA 2D (2 clusters)\")\n",
    "plt.xlabel(\"Eigenvalue 1\")\n",
    "plt.ylabel(\"Eigenvalue 2\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=aggclust2.labels_,cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "id": "ROl2zsHw5GV0",
    "outputId": "f274fcff-fd00-4426-f80a-8386ab95887c"
   },
   "outputs": [],
   "source": [
    "best_ss = []\n",
    "plt.figure()\n",
    "plt.title('Num Clusters vs. Silhouette Score (Agg, Average), w/ N components')\n",
    "for i in range(2,6):\n",
    "  x = range(2,15)\n",
    "  y = []\n",
    "  for j in x:\n",
    "    pca = PCA(n_components=i, svd_solver='full')\n",
    "    X = pca.fit_transform(data_matrix)\n",
    "    clustering = AgglomerativeClustering(n_clusters=j, linkage=\"average\").fit(X)\n",
    "    # print(clustering.labels_)\n",
    "    y.append(silhouette_score(X, clustering.labels_, metric='sqeuclidean'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.xlabel('# of clusters')\n",
    "  plt.ylabel('Silhouette Score')\n",
    "  plt.plot(x, y)\n",
    "\n",
    "  best_ss.append(max(y))\n",
    "\n",
    "  \n",
    "plt.legend(range(2,6))\n",
    "plt.show()\n",
    "  \n",
    "plt.figure()\n",
    "plt.title('Best Silhouette Score per Num Components: ' + str(round(max(best_ss), 3)))\n",
    "plt.xlabel('# of components')\n",
    "plt.ylabel('Max Silhouette Score')\n",
    "plt.plot(range(2,6), best_ss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "fZVLQqJg5PPC",
    "outputId": "927077f7-fc45-4eba-afae-a97e2a106c99"
   },
   "outputs": [],
   "source": [
    "# Best case scenario\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "X = pca.fit_transform(data_matrix)\n",
    "aggclust2 = AgglomerativeClustering(n_clusters=2, linkage=\"average\").fit(X)\n",
    "# print(clustering.labels_)\n",
    "print(silhouette_score(X, aggclust2.labels_, metric='sqeuclidean'))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Agglomerative Average-Linked Clustering Results on PCA 2D (2 clusters)\")\n",
    "plt.xlabel(\"Eigenvalue 1\")\n",
    "plt.ylabel(\"Eigenvalue 2\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=aggclust2.labels_,cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769
    },
    "colab_type": "code",
    "id": "ELx_JxnHu4bg",
    "outputId": "6d51367b-e53b-4c50-d99d-3dddfac9110f"
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "best_ss = []\n",
    "plt.figure()\n",
    "plt.title('Num Clusters vs. Silhouette Score (Gaussian), w/ N components')\n",
    "for i in range(2,6):\n",
    "  x = range(2,15)\n",
    "  y = []\n",
    "  for j in x:\n",
    "    pca = PCA(n_components=i, svd_solver='full')\n",
    "    X = pca.fit_transform(data_matrix)\n",
    "    gmm = GaussianMixture(n_components=i)\n",
    "    gmm.fit_predict(X)\n",
    "    # print(clustering.labels_)\n",
    "    y.append(silhouette_score(X, gmm.predict(X), metric='sqeuclidean'))\n",
    "  \n",
    "  \n",
    "  \n",
    "  plt.xlabel('# of clusters')\n",
    "  plt.ylabel('Silhouette Score')\n",
    "  plt.plot(x, y)\n",
    "\n",
    "  best_ss.append(max(y))\n",
    "\n",
    "  \n",
    "plt.legend(range(2,6))\n",
    "plt.show()\n",
    "  \n",
    "plt.figure()\n",
    "plt.title('Best Silhouette Score per Num Components: ' + str(round(max(best_ss), 3)))\n",
    "plt.xlabel('# of components')\n",
    "plt.ylabel('Max Silhouette Score')\n",
    "plt.plot(range(2,6), best_ss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1599
    },
    "colab_type": "code",
    "id": "0EWfEXXcvXmB",
    "outputId": "815b0d60-980e-4039-f6cd-39788a67e131"
   },
   "outputs": [],
   "source": [
    "# Best case scenario\n",
    "pca = PCA(n_components=4, svd_solver='full')\n",
    "# X = pca.fit_transform(nx.adjacency_matrix(g))\n",
    "gmm = GaussianMixture(n_components=5)\n",
    "labels = gmm.fit_predict(X)\n",
    "# print(clustering.labels_)\n",
    "# print(silhouette_score(X, specclust.labels_, metric='sqeuclidean'))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"GMM Clustering Results on PCA 2D (5 clusters)\")\n",
    "plt.xlabel(\"Eigenvalue 1\")\n",
    "plt.ylabel(\"Eigenvalue 2\")\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,cmap=plt.cm.jet)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "derivatives_graphs_data_request.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
